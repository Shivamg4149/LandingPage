{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat_2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-31a27367fe85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlEnd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFACIAL_LANDMARKS_IDXS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"left_eye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrEnd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFACIAL_LANDMARKS_IDXS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"right_eye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat_2"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "from __future__ import division\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def resize(img, width=None, height=None, interpolation=cv2.INTER_AREA):\n",
    "    global ratio\n",
    "    w, h = img.shape\n",
    "    if width is None and height is None:\n",
    "        return img\n",
    "    elif width is None:\n",
    "        ratio = height / h\n",
    "        width = int(w * ratio)\n",
    "        resized = cv2.resize(img, (height, width), interpolation)\n",
    "        return resized\n",
    "    else:\n",
    "        ratio = width / w\n",
    "        height = int(h * ratio)\n",
    "        resized = cv2.resize(img, (height, width), interpolation)\n",
    "        return resized\n",
    "######\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    for i in range(36,48):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    " \n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    print (A,B,C)\n",
    "\t# compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    " \n",
    "\t# return the eye aspect ratio\n",
    "    return ear\n",
    "camera = cv2.VideoCapture(1)\n",
    "\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat_2'\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "total=0\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if ret == False:\n",
    "        print('Failed to capture frame from camera. Check camera index in cv2.VideoCapture(0) \\n')\n",
    "        break\n",
    "\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_resized = resize(frame_grey, width=120)\n",
    "\n",
    "# Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "# second argument indicates that we should upsample the image 1 time. This\n",
    "# will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(frame_resized, 1)\n",
    "    \n",
    "    if len(dets) > 0:\n",
    "        for k, d in enumerate(dets):\n",
    "            shape = predictor(frame_resized, d)\n",
    "            shape = shape_to_np(shape)\n",
    "            leftEye= shape[lStart:lEnd]\n",
    "            rightEye= shape[rStart:rEnd]\n",
    "            leftEAR= eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "\t       \n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "            if ear>.29:\n",
    "                print (ear)\n",
    "                m=1\n",
    "                print ('o')\n",
    "                cv2.putText(frame, \"Eyes Open \", (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            else:\n",
    "                if m==1:\n",
    "                    total+=1\n",
    "                    m=0\n",
    "                    cv2.putText(frame, \"blink\" ,(250, 30),cv2.FONT_HERSHEY_SIMPLEX, 1.7, (0, 0, 0), 4)\n",
    "                print (ear)\n",
    "                print ('c')\n",
    "                \n",
    "                cv2.putText(frame, \"Eyes close\".format(total), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Total Count: {}\".format(total), (410, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(frame, (int(x/ratio), int(y/ratio)), 3, (255, 255, 255), -1)\n",
    "    cv2.imshow(\"image\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        camera.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
